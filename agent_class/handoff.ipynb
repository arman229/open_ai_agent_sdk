{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54510c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "# 1. AGENT LEVEL\n",
    "import os\n",
    "from agents import Agent, OpenAIChatCompletionsModel, AsyncOpenAI, Runner\n",
    "import asyncio\n",
    "try:\n",
    "\n",
    "    GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not GEMINI_API_KEY:\n",
    "        raise ValueError(\"GEMINI ApI key not found\")\n",
    "  \n",
    "    external_client = AsyncOpenAI(\n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        api_key=GEMINI_API_KEY,\n",
    "    )\n",
    "    model = OpenAIChatCompletionsModel(\n",
    "        model=\"gemini-2.0-flash\", openai_client=external_client\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a736c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premium_feature_enabled()\n",
      "premium True\n",
      "[ADV] get_weather()\n",
      "premium_feature_enabled()\n",
      "premium True\n",
      "London town is bright,\n",
      "Sunny skies are shining now,\n",
      "Day is clear and warm.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os \n",
    "from pydantic import BaseModel\n",
    "from agents import Agent, Runner, set_tracing_disabled, RunContextWrapper, function_tool\n",
    "from agents.run import AgentRunner, set_default_agent_runner\n",
    "\n",
    "\n",
    "\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    subscription_tier: str = \"free\"   \n",
    "    has_permission: bool = False\n",
    "\n",
    "\n",
    "def premium_feature_enabled(context: RunContextWrapper, agent: Agent) -> bool:\n",
    "    print(f\"premium_feature_enabled()\")\n",
    "    print(context.context.subscription_tier, context.context.subscription_tier in [\"premium\", \"enterprise\"])\n",
    "    return context.context.subscription_tier in [\"premium\", \"enterprise\"]\n",
    "\n",
    "@function_tool(is_enabled=premium_feature_enabled)\n",
    "def get_weather(city: str) -> str:\n",
    "    print(f\"[ADV] get_weather()\")\n",
    "    return \"Weather is sunny\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    context = UserContext(user_id=\"123\", subscription_tier=\"premium\", has_permission=True)\n",
    "    # context = UserContext(user_id=\"123\", subscription_tier=\"basic\", has_permission=True)\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"Call the get_weather tool with city 'London'\",\n",
    "        context=context,\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premium_feature_enabled()\n",
      "basic False\n",
      "Okay, I will do.\n",
      "Calling get_weather tool now.\n",
      "City is London.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os \n",
    "from pydantic import BaseModel\n",
    "from agents import Agent, Runner, set_tracing_disabled, RunContextWrapper, function_tool\n",
    "from agents.run import AgentRunner, set_default_agent_runner\n",
    "\n",
    "\n",
    "\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    subscription_tier: str = \"free\"   \n",
    "    has_permission: bool = False\n",
    "\n",
    "\n",
    "def premium_feature_enabled(context: RunContextWrapper, agent: Agent) -> bool:\n",
    "    print(f\"premium_feature_enabled()\")\n",
    "    print(context.context.subscription_tier, context.context.subscription_tier in [\"premium\", \"enterprise\"])\n",
    "    return context.context.subscription_tier in [\"premium\", \"enterprise\"]\n",
    "\n",
    "@function_tool(is_enabled=premium_feature_enabled)\n",
    "def get_weather(city: str) -> str:\n",
    "    print(f\"[ADV] get_weather()\")\n",
    "    return \"Weather is sunny\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # context = UserContext(user_id=\"123\", subscription_tier=\"premium\", has_permission=True)\n",
    "    context = UserContext(user_id=\"123\", subscription_tier=\"basic\", has_permission=True)\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"Call the get_weather tool with city 'London'\",\n",
    "        context=context,\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab52616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tool_code\n",
      "print(agent_manager.run(user_prompt=\"recursion in programming\"))\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from agents import handoff\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    subscription_tier: str = \"free\"  # free, premium, enterprise\n",
    "    has_permission: bool = False\n",
    "\n",
    "\n",
    "# This agent will use the custom LLM provider\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond for the user's request and delegate to the expert agent if needed.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "expert_agent = Agent(\n",
    "    name=\"Expert\",\n",
    "    instructions=\"You are an expert in the field of recursion in programming.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "\n",
    "agent.handoffs = [handoff(expert_agent, is_enabled=lambda ctx, agent: ctx.context.has_permission)]\n",
    "\n",
    "async def main():\n",
    "    context = UserContext(user_id=\"123\", subscription_tier=\"premium\", has_permission=False)\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"Call the expert agent and ask about recursion in programming\",\n",
    "        context=context,\n",
    "        max_turns=1\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998705a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxTurnsExceeded",
     "evalue": "Max turns (1) exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMaxTurnsExceeded\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.final_output)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\code\\open_ai_agent_sdk\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\code\\open_ai_agent_sdk\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     25\u001b[39m     context = UserContext(user_id=\u001b[33m\"\u001b[39m\u001b[33m123\u001b[39m\u001b[33m\"\u001b[39m, subscription_tier=\u001b[33m\"\u001b[39m\u001b[33mpremium\u001b[39m\u001b[33m\"\u001b[39m, has_permission=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m     28\u001b[39m         agent,\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCall the expert agent and ask about recursion in programming\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m         context=context,\n\u001b[32m     31\u001b[39m         max_turns=\u001b[32m1\u001b[39m\n\u001b[32m     32\u001b[39m     )\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\code\\open_ai_agent_sdk\\.venv\\Lib\\site-packages\\agents\\run.py:206\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, session)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03moutput is generated. The loop runs like so:\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m1. The agent is invoked with the given input.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m \u001b[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    205\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m runner.run(\n\u001b[32m    207\u001b[39m     starting_agent,\n\u001b[32m    208\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    209\u001b[39m     context=context,\n\u001b[32m    210\u001b[39m     max_turns=max_turns,\n\u001b[32m    211\u001b[39m     hooks=hooks,\n\u001b[32m    212\u001b[39m     run_config=run_config,\n\u001b[32m    213\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    214\u001b[39m     session=session,\n\u001b[32m    215\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\code\\open_ai_agent_sdk\\.venv\\Lib\\site-packages\\agents\\run.py:405\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn > max_turns:\n\u001b[32m    398\u001b[39m     _error_tracing.attach_error_to_span(\n\u001b[32m    399\u001b[39m         current_span,\n\u001b[32m    400\u001b[39m         SpanError(\n\u001b[32m   (...)\u001b[39m\u001b[32m    403\u001b[39m         ),\n\u001b[32m    404\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTurnsExceeded(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax turns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_turns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exceeded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    407\u001b[39m logger.debug(\n\u001b[32m    408\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    409\u001b[39m )\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mMaxTurnsExceeded\u001b[39m: Max turns (1) exceeded"
     ]
    }
   ],
   "source": [
    "from agents import handoff\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    subscription_tier: str = \"free\"  # free, premium, enterprise\n",
    "    has_permission: bool = False\n",
    "\n",
    "\n",
    "# This agent will use the custom LLM provider\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond for the user's request and delegate to the expert agent if needed.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "expert_agent = Agent(\n",
    "    name=\"Expert\",\n",
    "    instructions=\"You are an expert in the field of recursion in programming.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "\n",
    "agent.handoffs = [handoff(expert_agent, is_enabled=lambda ctx, agent: ctx.context.has_permission)]\n",
    "\n",
    "async def main():\n",
    "    context = UserContext(user_id=\"123\", subscription_tier=\"premium\", has_permission=True)\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"Call the expert agent and ask about recursion in programming\",\n",
    "        context=context,\n",
    "        max_turns=1\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63745a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, you've reached an expert on recursion in programming. Ask me anything! I can help you with understanding the core concepts, exploring different types of recursion, analyzing its advantages and disadvantages, comparing it to iterative approaches, and even debugging recursive code. Let me know what's on your mind.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents import handoff\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    subscription_tier: str = \"free\"  # free, premium, enterprise\n",
    "    has_permission: bool = False\n",
    "\n",
    "\n",
    "# This agent will use the custom LLM provider\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond for the user's request and delegate to the expert agent if needed.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "expert_agent = Agent(\n",
    "    name=\"Expert\",\n",
    "    instructions=\"You are an expert in the field of recursion in programming.\",\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "\n",
    "agent.handoffs = [handoff(expert_agent, is_enabled=lambda ctx, agent: ctx.context.has_permission)]\n",
    "\n",
    "async def main():\n",
    "    context = UserContext(user_id=\"123\", subscription_tier=\"premium\", has_permission=True)\n",
    "\n",
    "    result = await Runner.run(\n",
    "        agent,\n",
    "        \"Call the expert agent and ask about recursion in programming\",\n",
    "        context=context,\n",
    "        max_turns=2\n",
    "    )\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1298d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
